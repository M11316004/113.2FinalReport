# 113.2FinalReport
1. é–‹å•Ÿ Colab èˆ‡ä¸Šå‚³è³‡æ–™	
    é€²å…¥ Google ColabğŸ‘‰ å‰å¾€ï¼šhttps://colab.research.google.com/
   
3. Colab ä¸Šçš„ç¨‹å¼ç¢¼å€å¡Šï¼ˆä¾åºåŸ·è¡Œï¼‰
butterfly_dataset è³‡æ–™å¤¾æ”¾åœ¨ Google Drive ä¸­ï¼Œè·¯å¾‘ç‚ºï¼š /content/drive/MyDrive/LM/Project-Butterfly/butterfly_dataset/

å€å¡Š 1ï¼šæ›è¼‰ Google Drive
æŒ‡ä»¤	from google.colab import drive
drive.mount('/content/drive')
çµæœ	Mounted at /content/drive

å€å¡Š2ï¼šæª”æ¡ˆæ‰¹æ¬¡è™•ç†
å°‡æª”æ¡ˆæ ¼å¼çµ±ä¸€è½‰åŒ–æˆjpgæª”æ¡ˆæ ¼å¼ã€æª”æ¡ˆåç¨±ä¾ç…§img+ç·¨è™Ÿ.jpgæ–¹å¼å„²å­˜ã€‚

æŒ‡ä»¤	
import os
from PIL import Image

# âœ… åŸå§‹åœ–ç‰‡è³‡æ–™å¤¾ï¼ˆå«å­è³‡æ–™å¤¾ï¼‰
input_root = '/content/drive/MyDrive/LM/Project-Butterfly/butterfly_dataset/train_image'

# âœ… è¼¸å‡ºè³‡æ–™å¤¾ï¼ˆå°‡é‡å»ºç›¸åŒå­è³‡æ–™å¤¾çµæ§‹ï¼‰
output_root = '/content/drive/MyDrive/LM/Project-Butterfly/butterfly_dataset/train_image_jpg'

# å»ºç«‹è¼¸å‡ºä¸»è³‡æ–™å¤¾
os.makedirs(output_root, exist_ok=True)

# éæ­·æ‰€æœ‰å­è³‡æ–™å¤¾
for subdir in os.listdir(input_root):
    subdir_path = os.path.join(input_root, subdir)
    if os.path.isdir(subdir_path):
        print(f"ğŸ“ è™•ç†è³‡æ–™å¤¾: {subdir}")

        # å»ºç«‹å°æ‡‰è¼¸å‡ºå­è³‡æ–™å¤¾
        output_subdir = os.path.join(output_root, subdir)
        os.makedirs(output_subdir, exist_ok=True)

        # æ”¶é›† .jpeg / .jpg æª”æ¡ˆ
        image_files = sorted([
            f for f in os.listdir(subdir_path)
            if f.lower().endswith('.jpeg') or f.lower().endswith('.jpg')
        ])

        for idx, filename in enumerate(image_files, start=1):
            input_path = os.path.join(subdir_path, filename)
            output_filename = f"img{idx}.jpg"
            output_path = os.path.join(output_subdir, output_filename)

            try:
                with Image.open(input_path) as img:
                    if img.mode != 'RGB':
                        img = img.convert('RGB')
                    img.save(output_path, format='JPEG')
                    print(f"âœ… {subdir}/{output_filename}")
            except Exception as e:
                print(f"âŒ éŒ¯èª¤è™•ç† {filename} in {subdir}: {e}")


å€å¡Š 3ï¼šè³‡æ–™æ“´å……ï¼ˆData Augmentationï¼‰
è´è¶åœ–ç‰‡ï¼Œå…±å…­ç¨®åˆ†é¡ï¼Œå„é¡åˆ¥ç´„40-70 å¼µåœ–ã€‚ç¶“éè³‡æ–™æ“´å……ï¼Œæ¯é¡é”200 å¼µï¼Œå…± 1200 å¼µï¼Œåœ–åƒçµ±ä¸€èª¿æ•´ç‚º 150x150 åƒç´ ã€‚
æŒ‡ä»¤	
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
import numpy as np
from PIL import Image
from tqdm import tqdm

# åœ–ç‰‡å¤§å°èˆ‡æ“´å……ç›®æ¨™æ•¸é‡
IMG_HEIGHT, IMG_WIDTH = 150, 150
TARGET_PER_CLASS = 200

# åŸå§‹èˆ‡æ“´å……å¾Œçš„è³‡æ–™å¤¾è·¯å¾‘
original_data_dir = '/content/drive/MyDrive/LM/Project-Butterfly/butterfly_dataset/train_image'
augmented_data_dir = '/content/drive/MyDrive/LM/Project-Butterfly/augmented_dataset/train_image'  # â† æ³¨æ„é€™è£¡ç›´æ¥å»ºç«‹åœ¨ train_image å…§

# å»ºç«‹è³‡æ–™å¢å¼·å™¨
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# é€é¡åˆ¥åŸ·è¡Œæ“´å……
for class_name in os.listdir(original_data_dir):
    class_path = os.path.join(original_data_dir, class_name)
    if not os.path.isdir(class_path):
        continue

    save_class_dir = os.path.join(augmented_data_dir, class_name)
    os.makedirs(save_class_dir, exist_ok=True)

    images = [img for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]
    num_existing = len(images)
    print(f"ğŸ” é¡åˆ¥ã€Œ{class_name}ã€ç›®å‰æœ‰ {num_existing} å¼µåœ–ç‰‡ï¼Œå°‡æ“´å……è‡³ {TARGET_PER_CLASS} å¼µ")

    image_counter = 0

    # å„²å­˜åŸåœ–ï¼ˆresize å¾Œï¼‰åˆ°æ“´å……è³‡æ–™å¤¾
    for img_name in images:
        src = os.path.join(class_path, img_name)
        dst = os.path.join(save_class_dir, f"original_{img_name}")
        try:
            img = Image.open(src)
            img = img.resize((IMG_WIDTH, IMG_HEIGHT))
            img.save(dst)
            image_counter += 1
        except:
            print(f"âš ï¸ ç„¡æ³•è™•ç†åœ–ç‰‡ï¼š{img_name}")

    # åŸ·è¡Œåœ–ç‰‡æ“´å……ç›´åˆ°é”åˆ°ç›®æ¨™å¼µæ•¸
    for img_name in images:
        if image_counter >= TARGET_PER_CLASS:
            break

        img_path = os.path.join(class_path, img_name)
        try:
            img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
            x = img_to_array(img)
            x = np.expand_dims(x, axis=0)

            for batch in datagen.flow(x, batch_size=1):
                new_name = f"aug_{image_counter:04d}.jpg"
                save_path = os.path.join(save_class_dir, new_name)
                Image.fromarray((batch[0] * 255).astype(np.uint8)).save(save_path)
                image_counter += 1
                if image_counter >= TARGET_PER_CLASS:
                    break
        except:
            print(f"âš ï¸ æ“´å……å¤±æ•—ï¼š{img_name}")

    print(f"âœ… é¡åˆ¥ã€Œ{class_name}ã€è™•ç†å®Œæˆï¼Œå…± {image_counter} å¼µåœ–ç‰‡ã€‚\n")



å€å¡Š 4ï¼šå¼•å…¥å¿…è¦å¥—ä»¶ä¸¦è¨­å®šè·¯å¾‘å¼•å…¥å¿…è¦å¥—ä»¶ä¸¦è¨­å®šè·¯å¾‘
æŒ‡ä»¤	
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import numpy as np
import os

# è¨­å®šè·¯å¾‘èˆ‡åƒæ•¸
DATASET_PATH = '/content/drive/MyDrive/LM/Project-Butterfly/augmented_dataset/train_image'  # æ›¿æ›æˆä½ å¯¦éš›çš„è·¯å¾‘
IMG_HEIGHT, IMG_WIDTH = 150, 150
BATCH_SIZE = 32
EPOCHS = 10

å€å¡Š 5ï¼šè®€å–èˆ‡æ“´å¢å½±åƒè³‡æ–™
æŒ‡ä»¤	train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    DATASET_PATH,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    DATASET_PATH,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

class_names = list(train_generator.class_indices.keys())
print("é¡åˆ¥åç¨±ï¼š", class_names)



å€å¡Š 6ï¼šå»ºç«‹ä¸¦è¨“ç·´ CNN æ¨¡å‹
æŒ‡ä»¤	
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(len(class_names), activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS
)



å€å¡Š 7ï¼šå„²å­˜æ¨¡å‹åˆ° Google Drive
æŒ‡ä»¤	
model.save('/content/drive/MyDrive/LM/Project-Butterfly/butterfly_dataset/butterfly_cnn_model.h5')


å€å¡Š 8ï¼šä½¿ç”¨æ¨¡å‹é€²è¡Œåœ–ç‰‡é æ¸¬
æŒ‡ä»¤	
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
from tensorflow.keras.preprocessing import image
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

# âœ… æ¨¡å‹èˆ‡åŸºæœ¬è¨­å®š
model = tf.keras.models.load_model('/content/drive/MyDrive/LM/Project-Butterfly/butterfly_dataset/butterfly_cnn_model.h5')
class_names = [
    'class1_Byasa impediens febanus_40',
    'class2_Delias pasithoe_63',
    'class3_Papilio memnon_51',
    'class4_Danaus genutia_65',
    'class5_Pieris rapae_49',
    'class6_Euploea tulliolus_66'
]
IMG_WIDTH, IMG_HEIGHT = 150, 150

# âœ… è³‡æ–™å¤¾è¨­å®š
predict_folder = '/content/drive/MyDrive/LM/Project-Butterfly/butterfly_dataset/test_images'
save_folder = '/content/drive/MyDrive/LM/Project-Butterfly/prediction_results/annotated_images'
csv_path = '/content/drive/MyDrive/LM/Project-Butterfly/prediction_results/prediction_log_CNN.csv'
os.makedirs(save_folder, exist_ok=True)

# âœ… é æ¸¬èˆ‡è¨˜éŒ„å®¹å™¨
log_data = {
    'filename': [], 'predicted_class': [], 'true_class': [], 'confidence': [], 'match': []
}
y_true = []
y_pred = []

# âœ… é¡åˆ¥åç¨±å°æ‡‰è¡¨ï¼ˆå¾ class_names æŠ½å‡ºé¡åˆ¥åç¨±ï¼‰
true_labels = [name.split('_', 1)[1].rsplit('_', 1)[0] for name in class_names]

# âœ… é æ¸¬å‡½å¼
def predict_images_from_folder(folder_path, model, class_names):
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    for img_file in image_files:
        img_path = os.path.join(folder_path, img_file)
        img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
        img_array = image.img_to_array(img) / 255.0
        img_array = tf.expand_dims(img_array, axis=0)
        prediction = model.predict(img_array, verbose=0)

        predicted_class_full = class_names[np.argmax(prediction)]
        predicted_class_name = predicted_class_full.split('_', 1)[1].rsplit('_', 1)[0]
        confidence = np.max(prediction)

        # ğŸ” å˜—è©¦å¾æª”åä¸­æ‰¾å‡ºçœŸå¯¦é¡åˆ¥
        matched_class = None
        for label in true_labels:
            if label.lower().replace(' ', '') in img_file.lower().replace('_', '').replace(' ', ''):
                matched_class = label
                break
        result_symbol = 'O' if matched_class == predicted_class_name else 'X'

        # âœ… è¨˜éŒ„è³‡è¨Š
        y_true.append(matched_class if matched_class else "Unknown")
        y_pred.append(predicted_class_name)

        log_data['filename'].append(img_file)
        log_data['predicted_class'].append(predicted_class_name)
        log_data['true_class'].append(matched_class if matched_class else "Unknown")
        log_data['confidence'].append(round(confidence, 4))
        log_data['match'].append(result_symbol)

        # âœ… å¯è¦–åŒ–çµæœå„²å­˜åœ–ç‰‡
        fig, ax = plt.subplots(figsize=(4, 4))
        ax.imshow(image.load_img(img_path))
        ax.set_title(f'{img_file}\né æ¸¬: {predicted_class_name} ({confidence:.2f})', fontsize=9)
        ax.text(0.95, 0.05, result_symbol, transform=ax.transAxes,
                fontsize=18, fontweight='bold', color='green' if result_symbol == 'O' else 'red',
                ha='right', va='bottom')
        ax.axis('off')
        save_path = os.path.join(save_folder, f'checked_{img_file}')
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()

        print(f"âœ”ï¸ åœ–ç‰‡: {img_file} â†’ é æ¸¬: {predicted_class_name}ï¼ˆä¿¡å¿ƒå€¼: {confidence:.2f}ï¼‰ â†’ æ¨™è¨»ï¼š{result_symbol}")

# âœ… åŸ·è¡Œé æ¸¬
predict_images_from_folder(predict_folder, model, class_names)

# âœ… åŒ¯å‡º CSV
df = pd.DataFrame(log_data)
df.to_csv(csv_path, index=False)
print(f"\nğŸ“„ é æ¸¬è¨˜éŒ„å·²å„²å­˜ï¼š{csv_path}")

# âœ… æ··æ·†çŸ©é™£èˆ‡å ±å‘Š
print("\nğŸ“Š æ··æ·†çŸ©é™£ï¼š")
labels = sorted(list(set(y_true) & set(y_pred)))
cm = confusion_matrix(y_true, y_pred, labels=labels)
print(cm)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
fig, ax = plt.subplots(figsize=(8, 6))
disp.plot(cmap='Blues', ax=ax, xticks_rotation=45)
plt.title("Butterfly Classification Confusion Matrix")
plt.tight_layout()
plt.savefig('/content/drive/MyDrive/LM/Project-Butterfly/prediction_results/confusion_matrix.png')
plt.show()

# âœ… åˆ†é¡å ±å‘Š
print("\nğŸ“‹ Classification Report:")
report = classification_report(y_true, y_pred, labels=labels, zero_division=0)
print(report)

